### Описание задачи
Цель проекта:
Создать сервис, который принимает на вход набор строк, содержащих "грязные" данные, и на выходе формирует набор "золотых записей" — это объединенные и очищенные записи, которые содержат корректные и обогащенные данные.

### Основные компоненты сервиса

1. Входные данные:
   - Входные данные представляют собой список строк, где каждая строка может содержать частичные или ошибочные записи. Это могут быть как текстовые данные, так и данные в формате JSON или CSV.
   
2. Обработка данных:
   - Очистка данных: На этом этапе необходимо удалить дубликаты, пробелы, специальные символы и исправить общие ошибки, такие как неправильный формат даты или опечатки в именах.
   - Нормализация данных: Это включает в себя приведение данных к единому формату. Например, все имена могут быть преобразованы в нижний регистр, а даты — в формат YYYY-MM-DD.

3. Обогащение данных:
   - Обогащение происходит за счет объединения данных из различных источников. Например, можно использовать внешние API для получения дополнительной информации о местоположении или организации, если это применимо. 
   - Также может быть полезно интегрировать справочники, например, для корректного сопоставления идентификаторов или нахождения синонимов для названий.

4. Составление золотых записей:
   - После очистки и обогащения данных необходимо объединить записи, которые относятся к одному объекту. 
   - Для этого могут использоваться алгоритмы сопоставления строк (string matching) и алгоритмы кластеризации.

5. Выходные данные:
   - Сервис должен возвращать очищенный и обогащенный набор данных (золотые записи) в том формате, который указан (например, JSON или CSV).
   - Кроме того, возможно создание отчетов о том, сколько записей было обработано, сколько из них были очищены, а сколько — объединены.

### Реализация

1. Реализована валидация числовых полей в соответствии с правилами заполнения, а также проверка номера телефона и почты на соответствие маске
2. Реализован алгоритм расчета расстояний Левенштейна
3. Удалось добиться корректной работы алгоритма на датасете в 5000 записей, на датасете в 50000 записей время обратки существенно увеличивается. Добиться обработки полного датасета в 1000000 записей не удалось (выявлены ошибки, которые не успели исправить).


### Заключение
Поиск дубликатов и разработка алгоритмов объединения данных - актуальная задача, применимая в различных областях бизнеса.
Не удалось, но мы старались :)
